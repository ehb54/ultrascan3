Stampede

Ask: shared memory accessible on MIC(s) via ipc or other method(?)

I am thinking we want to create 1 or 2 mpi's per MIC and thread them
Keep all sh data on mic

mic sets up worker threads to compute_I

forget commuincators
master keeps track

if mic: setup threads and wait for shutdown or computation request
test if we can compute_I threaded with mutex

module swap mvapich2 impi
srun --pty -n 16 -t 00:30:00 -p development -A TG-TRA120007 /bin/bash -l

mpicxx -O3 -mmic  mpitest.c -o mpitest_mic
mpicxx -O3 -xhost mpitest.c -o mpitest_xhost

mpiicpc -O3 -mmic  mpitest.c -o mpitest_mic
mpiicpc -O3 -xhost mpitest.c -o mpitest_xhost

mpic++ -O3 -mmic  mpitest.c -o mpitest_mic
mpic++ -O3 -xhost mpitest.c -o mpitest_xhost

mpicc -O3 -mmic  mpitest.c -o mpitest_mic
mpicc -O3 -xhost mpitest.c -o mpitest_xhost

env MIC_PPN=32 ibrun.symm -m ./mpitest_mic -c ./mpitest_xhost
ibrun.symm -m ./mpitest_mic
ibrun.symm -c ./mpitest_xhost

Use the "$MIC_PPN" and "$MIC_OMP_NUM_THREADS" environment variables to set the number of tasks and threads for each MIC

making libqt for mic will be a bear... have to create pure c++/mpi version

mpicxx -O3 -mmic  mpitest2.c -o mpitest_mic
mpicxx -O3 -xhost mpitest2.c -o mpitest_xhost

mpicxx -O3 -mmic  mpitest2.c -o mpitest_mic; mpicxx -O3 -xhost mpitest2.c -o mpitest_xhost



Process affinity:
-> numactl
numactl <options> ./a.out
tacc_affinity
see "hybrid batch script"
sched_set_affinity() (openmp or pthreads)
taskset

compiler options

(not on mic) -xAVX -ipo
 
-fast (not on MPI for mvapich2, maybe intel stack)

-O3 may not be best

-no-prec-div

-O1 may be smaller

MKL:
http://software.intel.com/sites/products/documentation/doclib/mkl_sa/11/mklman/index.htm


virtual topologies (in MPI) MPI_Cart_create

todo:



more timing improvements
try to go fully float
remove vector / other stl ?

controlled scatter (non-blocking sends )


MPI_Wtime overhead really slows things down.

maybe more with fully float?
more optimization of legendre/sphbes code
(inline ?)

hetrogenous distribute with mic

more with legendre
(explicit inline functions)
test new logic flags


----------
compare I (finish off testing)
seems ok for 1 atom ?
possible compare A ?

A difference (esp. 0th order! harms = 1)

compare Y, J ?

 cublic spline: pull from us_saxs_util to build for 
max harmonics
grid resolution
max x
store relevant data (c arrays)
apply spline to grid and compare with original function
run as replacement for shbes
time!


compute via sphbes: 5400ms
compute via natural_spline (full vectoring): 10ms

compute via sphbes: 40830ms
compute via natural_spline (full vectoring): 50ms

:)

done->have shs build c tables
done->write code to work off c tables for external usage
done->integrate new shs_use to shd

todo->
-> put in us_pm
-> put in us_hydrodyn_saxs_iqq_sh

verify correct values
.1 -> interpolate to .01 vs sphbes & .01

time again!



